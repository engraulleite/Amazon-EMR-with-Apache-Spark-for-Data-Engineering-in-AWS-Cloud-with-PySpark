# Amazon-EMR-with-Apache-Spark-for-Data-Engineering-in-AWS-Cloud-with-PySpark
In this project we created a EMR cluster with Spark, Hadoop and Zeppelin to process a PySpark job. The goal was find the 10 restaurants with the highest number of sanitary violations.
The public dataset is about restaurants in Seattle-US. Link:
https://data.kingcounty.gov/Health-Wellness/Food-Establishment-Inspection-Data/f29f-zza5

## Services provided:
- [x] Creating an AWS S3 bucket
- [x] EMR cluster configuration
- [x] Data processing with PySpark and SQL
      
## Developed Skills:
- [x] PySpark
- [x] Amazon Elastic MapReduce (EMR)
- [x] SQL
